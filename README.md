# üéµ Music Genre Classification with MLOps

<p align="center">
  <img src="images/music-genre-classification-project.png" alt="Music Genre Classification Project">
</p>

## **Context**

Music genre classification is a challenging task in machine learning, as it requires analyzing complex audio data and identifying patterns unique to specific genres. With the rise of digital music platforms, automating this classification has become increasingly important for organizing, recommending, and retrieving music effectively.

## **Practical Applications**

- Automated music organization and tagging.

- Music recommendation systems for streaming platforms.

- Enhancing search and discovery features in digital music libraries.

- Assisting creators in identifying or categorizing their work.

- Audio Analysis Tools: Develop tools for musicologists and researchers to analyze genre trends.

- Educational Platforms: Aid in music education by categorizing and recommending tracks for learning.

## üéØ **What This Project Does**

This project implements a **complete MLOps pipeline** for music genre classification using deep learning. It predicts music genres from audio files using a CNN model trained on MFCC features, classifying into 10 genres: rock, classical, metal, disco, blues, reggae, country, hiphop, jazz, and pop.

The application is designed to be user-friendly and operates via a Flask API, which allows users to upload an audio file and receive the predicted genre in JSON format. It goes beyond traditional machine learning by incorporating production-ready infrastructure, monitoring, and orchestration components.


### **üöÄ Key Features**
- **üéµ Real-time Prediction API** with Flask + Nginx
- **ü§ñ CNN Model** trained on MFCC features (>75% accuracy)
- **üî¨ MLflow Integration** for experiment tracking and model registry
- **üåä Prefect Workflows** for orchestrated training pipelines
- **üìä Model Monitoring** with Evidently + Prometheus + Grafana
- **üê≥ Production-Ready** containerized deployment
- **‚úÖ Code quality & Comprehensive Testing** with CI/CD automation

This project serves as a **comprehensive MLOps template** demonstrating industry best practices for machine learning systems in production.

---

## üìñ **Documentation Structure**

| Document | Description | Quick Links |
|----------|-------------|-------------|
| **[üöÄ Test & Run Guide](docs/TEST_RUN.md)** | Get up and running in 5 minutes | [Install](docs/QUICK_START.md#installation) ‚Ä¢ [Run](docs/QUICK_START.md#running) ‚Ä¢ [Test](docs/QUICK_START.md#testing) |
| **[üèóÔ∏è Architecture Guide](docs/ARCHITECTURE.md)** | Technical architecture and design | [Structure](docs/ARCHITECTURE.md#project-structure) ‚Ä¢ [Services](docs/ARCHITECTURE.md#service-architecture) ‚Ä¢ [Data Flow](docs/ARCHITECTURE.md#data-flow) |
| **[üîÑ API Documentation](docs/API.md)** | Complete API reference and examples | [Endpoints](docs/API.md#-api-endpoints) ‚Ä¢ [Integration](docs/API.md#-model-loading-strategy) |
| **[üìä Monitoring Guide](docs/MONITORING.md)** | Model monitoring and observability | [Dashboards](docs/MONITORING.md#dashboards) ‚Ä¢ [Alerts](docs/MONITORING.md#alerts) ‚Ä¢ [Metrics](docs/MONITORING.md#metrics) |
| **[üåä Training Pipeline](docs/TRAINING.md)** | ML pipeline and experiment management | [Prefect](docs/TRAINING.md#prefect-workflow-orchestration) ‚Ä¢ [MLflow](docs/TRAINING.md#mlflow-experiment-tracking) ‚Ä¢ [Automation](docs/TRAINING.md#pipeline-triggers) |
| **[üõ†Ô∏è Model Development Guide](docs/MODEL_DEV.md)** | From raw audio dataset to a deep learning model | [Dataset](docs/MODEL_DEV.md#dataset-description) ‚Ä¢ [Architecture](docs/MODEL_DEV.md#-model-architecture) ‚Ä¢ [Notebooks](docs/MODEL_DEV.md#notebooks) |

---

## ‚ö° **Quick Start Guide**

The easiest way to run a first prediction for testing the app is to use **docker-compose**.  
And the fastest way is to run it in a **GitHub codespace**.

### **Prerequisites (include in a codespace)**
- **Python 3.11+** 
- **Docker & Docker Compose**
- **Git**

### **1Ô∏è‚É£ Create a Codespace on main**

### **2Ô∏è‚É£ Start only the required services for inference**
```bash
docker-compose up --build mlflow api nginx -d
```
### **3Ô∏è‚É£ Test**
```bash
# With an audio file in the test folder:
python client.py --file audio_files_test/blues.00000.wav

# Test the entire folder:
python client.py --file audio_files_test/
# or with Makefile:
make run-client
```
The first prediction is slow (20-30s) because:

- MLflow model loading: Downloads model from registry
- Library initialization: librosa, tensorflow, etc.
- Audio processing: MFCC feature extraction
- Model inference: First prediction through neural network

Subsequent predictions will be much faster (almost instantaneous) since the model stays loaded in memory.


üìñ **Want to go further?** See the [Complete Test & Run Guide](docs/TEST_RUN.md)

---

## üèóÔ∏è **Project Architecture**

```mermaid
graph TB
    Client[üéµ Client] --> Nginx[üåê Nginx :80]
    Nginx --> API[üöÄ Flask API :5050]
    API --> MLflow[üî¨ MLflow :5000]
    API --> Monitor[üìä Monitoring :8000]
    
    Prefect[üåä Prefect :4200] --> Worker[üë∑ Worker]
    Worker --> MLflow
    Postgres[üóÑÔ∏è PostgreSQL] --> Prefect
    
    Monitor --> Prometheus[üìà Prometheus :9091]
    Prometheus --> Grafana[üìä Grafana :3000]
    
    subgraph "Model Training"
        Worker --> CNN[üß† CNN Model]
        CNN --> MFCC[üéµ MFCC Features]
    end
    
    subgraph "Monitoring Stack"
        Monitor --> Evidently[üîç Evidently]
        Evidently --> Drift[üìâ Drift Detection]
    end
```


üìñ **Deep dive into architecture**: [Architecture Guide](docs/ARCHITECTURE.md)

---

## üóÇÔ∏è **Project Structure**

```
music-genre-classification/
‚îú‚îÄ‚îÄ üìÅ api/                     # Production API service
‚îú‚îÄ‚îÄ üìÅ classifier/              # ML training pipeline  
‚îú‚îÄ‚îÄ üìÅ monitoring/              # Model monitoring stack
‚îú‚îÄ‚îÄ üìÅ nginx/                   # Reverse proxy
‚îú‚îÄ‚îÄ üìÅ tests/                   # Comprehensive test suite
‚îú‚îÄ‚îÄ üìÅ docs/                    # üìñ Documentation
‚îú‚îÄ‚îÄ üìÅ notebooks/               # Jupyter experiments
‚îú‚îÄ‚îÄ üê≥ docker-compose.yaml     # Service orchestration
‚îú‚îÄ‚îÄ üîß Makefile                # Development commands
‚îî‚îÄ‚îÄ üìã README.md               # This file
```

üìñ **Detailed structure**: [Architecture Guide ‚Üí Project Structure](docs/ARCHITECTURE.md#project-structure)

---

## **Conclusion & future improvements**

### MLOps Architecture
This project implements a production-ready MLOps pipeline featuring containerized microservices with Flask API, Nginx reverse proxy, and comprehensive monitoring through Prometheus and Grafana. The architecture leverages Prefect for workflow orchestration, MLflow for experiment tracking and model registry, and Evidently for model drift detection. Key strengths include automated CI/CD pipelines, real-time monitoring, and scalable containerized deployment.

**Future MLOps improvements:**
* Complete Prefect flow integration from raw data ingestion to model deployment
* Automated hyperparameter optimization workflows with CI integration
* Enhanced data source diversity for improved Evidently monitoring metrics
* Cloud-native streaming deployment infrastructure
* Continuous deployment automation through Prefect scheduling

### ML Model Development
This project demonstrates the application of a Convolutional Neural Network (CNN) for music genre classification using the GTZAN dataset. The relatively high accuracy achieved (> 75% on validation and test sets) highlights the strength of CNNs in extracting and leveraging audio features like MFCCs for genre prediction.

However, while the GTZAN dataset has been foundational in advancing music genre classification, it's essential to be aware of its limitations (limited diversity, quality issues, overuse and overfitting). Researchers and developers often use additional or alternative datasets to achieve more robust and generalizable results.

**Future model improvements:**
* Data Augmentation: Enhancing the dataset with techniques like pitch shifting, time stretching, or adding noise to increase diversity
* Advanced Architectures: Exploring models like spectrogram-based transformers or hybrid CNN-RNN architectures for improved feature extraction and temporal modeling
* Dataset Quality: Leveraging larger, more diverse, and well-labeled datasets to enhance robustness
* Feature Engineering: Experimenting with additional audio features beyond MFCCs, such as chroma features or spectral contrast

This project provides a comprehensive MLOps template demonstrating industry best practices for machine learning systems in production, serving as a solid foundation for music genre classification while acknowledging opportunities for refinement and further exploration.



## üéì **Learning Resources**

### **üìö Understand the Technologies**
- **[CNN for Audio](docs/MODEL_DEV.md#model-architecture)**: How the model processes MFCC features
- **[MLOps Pipeline](docs/TRAINING.md)**: End-to-end ML workflow automation
- **[Model Monitoring](docs/MONITORING.md)**: Production model observability
- **[API Design](docs/API.md)**: RESTful service architecture

### **üõ†Ô∏è Hands-On Tutorials**
- **[Training Your Own Model](docs/TRAINING.md#custom-training)**: Modify and retrain
- **[Custom Monitoring](docs/MONITORING.md#custom-dashboards)**: Create your own dashboards  
- **[API Integration](docs/API.md#integration-examples)**: Integrate with your app

### **üìä Notebooks & Experiments**
- **[EDA.ipynb](notebooks/EDA.ipynb)**: Exploratory data analysis
- **[data_preparation.ipynb](notebooks/data_preparation.ipynb)**: Feature engineering
- **[model_NN_classification.ipynb](notebooks/model_NN_classification.ipynb)**: Model selection
- **[data_testing.ipynb](monitoring/data_testing.ipynb)**: Ground-truth dataset for monitoring

---

## üìÑ **License**

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## üôè **Acknowledgments**

- **GTZAN Dataset**: George Tzanetakis for the foundational music genre dataset
- **Alexey Grigorev**: for the creation and supervision of these ML & MLOps Zoomcamp without which this project would not have been possible. I would like to thank him as well for all his valuable teaching and support.
- **MLOps Zoomcamp Community**: For inspiring production-ready ML practices
- **Open Source Libraries**: TensorFlow, MLflow, Prefect, Evidently, and more

---

## üìû **Support, Contribution & Community**

- **üêõ Issues**: [GitHub Issues](https://github.com/arsonor/music-genre-classification-with-deep-learning/issues)
- **üì§ Submit**: [Create a pull request](https://github.com/arsonor/music-genre-classification-with-deep-learning/pulls)
- **üìß Contact**: [Linkedin](https://www.linkedin.com/in/martindornic/)
- **üìñ Wiki**: [Project Wiki](https://github.com/arsonor/music-genre-classification-with-deep-learning/wiki)

---

<p align="center">
  <strong>üéµ Ready to classify some music? </strong><br>
  <a href="docs/TEST_RUN.md">Get Started here ‚Üí</a>
</p>