# ğŸµ Music Genre Classification with MLOps

<p align="center">
  <img src="images/music-genre-classification-project.png" alt="Music Genre Classification Project">
</p>

## Context

Music genre classification is a challenging task in machine learning, as it requires analyzing complex audio data and identifying patterns unique to specific genres. With the rise of digital music platforms, automating this classification has become increasingly important for organizing, recommending, and retrieving music effectively.

## Practical Applications

- Automated music organization and tagging.

- Music recommendation systems for streaming platforms.

- Enhancing search and discovery features in digital music libraries.

- Assisting creators in identifying or categorizing their work.

- Audio Analysis Tools: Develop tools for musicologists and researchers to analyze genre trends.

- Educational Platforms: Aid in music education by categorizing and recommending tracks for learning.

## ğŸ¯ **What This Project Does**

This project implements a **complete MLOps pipeline** for music genre classification using deep learning. It predicts music genres from audio files using a CNN model trained on MFCC features, classifying into 10 genres: rock, classical, metal, disco, blues, reggae, country, hiphop, jazz, and pop.

The application is designed to be user-friendly and operates via a Flask API, which allows users to upload an audio file and receive the predicted genre in JSON format. It goes beyond traditional machine learning by incorporating production-ready infrastructure, monitoring, and orchestration components.


### **ğŸš€ Key Features**
- **ğŸµ Real-time Prediction API** with Flask + Nginx
- **ğŸ¤– CNN Model** trained on MFCC features (>75% accuracy)
- **ğŸ”¬ MLflow Integration** for experiment tracking and model registry
- **ğŸŒŠ Prefect Workflows** for orchestrated training pipelines
- **ğŸ“Š Model Monitoring** with Evidently + Prometheus + Grafana
- **ğŸ³ Production-Ready** containerized deployment
- **âœ… Code quality & Comprehensive Testing** with CI/CD automation

This project serves as a **comprehensive MLOps template** demonstrating industry best practices for machine learning systems in production.

---

## ğŸ“– **Documentation Structure**

| Document | Description | Quick Links |
|----------|-------------|-------------|
| **[ğŸš€ Test & Run Guide](docs/TEST_RUN.md)** | Get up and running in 5 minutes | [Install](docs/QUICK_START.md#installation) â€¢ [Run](docs/QUICK_START.md#running) â€¢ [Test](docs/QUICK_START.md#testing) |
| **[ğŸ—ï¸ Architecture Guide](docs/ARCHITECTURE.md)** | Technical architecture and design | [Model](docs/ARCHITECTURE.md#model-architecture) â€¢ [Services](docs/ARCHITECTURE.md#service-architecture) â€¢ [Data Flow](docs/ARCHITECTURE.md#data-flow) |
| **[ğŸ³ Deployment Guide](docs/DEPLOYMENT.md)** | Docker, production setup, scaling | [Docker Compose](docs/DEPLOYMENT.md#docker-compose) â€¢ [Production](docs/DEPLOYMENT.md#production) â€¢ [Scaling](docs/DEPLOYMENT.md#scaling) |
| **[ğŸ”„ API Documentation](docs/API.md)** | Complete API reference and examples | [Endpoints](docs/API.md#endpoints) â€¢ [Examples](docs/API.md#examples) â€¢ [Integration](docs/API.md#integration) |
| **[ğŸ› ï¸ Development Guide](docs/DEVELOPMENT.md)** | Development workflow and contribution | [Setup](docs/DEVELOPMENT.md#setup) â€¢ [Testing](docs/DEVELOPMENT.md#testing) â€¢ [Contributing](docs/DEVELOPMENT.md#contributing) |
| **[ğŸ“Š Monitoring Guide](docs/MONITORING.md)** | Model monitoring and observability | [Dashboards](docs/MONITORING.md#dashboards) â€¢ [Alerts](docs/MONITORING.md#alerts) â€¢ [Metrics](docs/MONITORING.md#metrics) |
| **[ğŸŒŠ Training Pipeline](docs/TRAINING.md)** | ML pipeline and experiment management | [Prefect](docs/TRAINING.md#prefect-workflows) â€¢ [MLflow](docs/TRAINING.md#mlflow-tracking) â€¢ [Automation](docs/TRAINING.md#automation) |

---

## âš¡ **Quick Start**
# ğŸš€ Quick Start Guide

Get the music genre classification MLOps pipeline running in 5 minutes!

### **Prerequisites**
- **Python 3.11+** 
- **Docker & Docker Compose**
- **Git**

### **1ï¸âƒ£ Setup**
```bash
git clone https://github.com/arsonor/music-genre-classification-with-deep-learning
cd music-genre-classification-with-deep-learning

# Complete development setup (installs dependencies + pre-commit hooks)
make dev-setup  # Or: bash setup_tests.sh
```

### **2ï¸âƒ£ Start All Services**
```bash
# Start entire MLOps stack
make docker-up

# Or alternatively:
docker-compose up --build -d
```

### **3ï¸âƒ£ Test**
```bash
# Test with sample audio
make run-client

# Or manually:
curl -X POST -F "file=@test/blues.00000.wav" http://localhost/predict
```

### **4ï¸âƒ£ Access Services**
- **ğŸµ API**: http://localhost (Nginx reverse proxy)
- **ğŸ”¬ MLflow**: http://localhost:5000 (Experiment tracking)
- **ğŸŒŠ Prefect**: http://localhost:4200 (Workflow orchestration)  
- **ğŸ“Š Grafana**: http://localhost:3000 (Monitoring dashboards)
- **ğŸ”¥ Prometheus**: http://localhost:9091 (Metrics collection)


ğŸ“– **Need more details?** See the [Complete Quick Start Guide](docs/QUICK_START.md)

---

## ğŸ—ï¸ **Project Architecture**

```mermaid
graph TB
    Client[ğŸµ Client] --> Nginx[ğŸŒ Nginx :80]
    Nginx --> API[ğŸš€ Flask API :5050]
    API --> MLflow[ğŸ”¬ MLflow :5000]
    API --> Monitor[ğŸ“Š Monitoring :8000]
    
    Prefect[ğŸŒŠ Prefect :4200] --> Worker[ğŸ‘· Worker]
    Worker --> MLflow
    Postgres[ğŸ—„ï¸ PostgreSQL] --> Prefect
    
    Monitor --> Prometheus[ğŸ“ˆ Prometheus :9091]
    Prometheus --> Grafana[ğŸ“Š Grafana :3000]
    
    subgraph "Model Training"
        Worker --> CNN[ğŸ§  CNN Model]
        CNN --> MFCC[ğŸµ MFCC Features]
    end
    
    subgraph "Monitoring Stack"
        Monitor --> Evidently[ğŸ” Evidently]
        Evidently --> Drift[ğŸ“‰ Drift Detection]
    end
```

### **Core Components**
- **ğŸµ Prediction API**: Flask service with model inference
- **ğŸ§  CNN Model**: Architecture optimized for MFCC features  
- **ğŸ”¬ Experiment Tracking**: MLflow for model versioning
- **ğŸŒŠ Workflow Orchestration**: Prefect for training automation
- **ğŸ“Š Model Monitoring**: Evidently + Prometheus + Grafana
- **ğŸ³ Infrastructure**: Docker Compose orchestration

ğŸ“– **Deep dive into architecture**: [Architecture Guide](docs/ARCHITECTURE.md)

---

## ğŸ—‚ï¸ **Project Structure**

```
music-genre-classification/
â”œâ”€â”€ ğŸ“ api/                     # Production API service
â”œâ”€â”€ ğŸ“ classifier/              # ML training pipeline  
â”œâ”€â”€ ğŸ“ monitoring/              # Model monitoring stack
â”œâ”€â”€ ğŸ“ nginx/                   # Reverse proxy
â”œâ”€â”€ ğŸ“ tests/                   # Comprehensive test suite
â”œâ”€â”€ ğŸ“ docs/                    # ğŸ“– Documentation
â”œâ”€â”€ ğŸ“ notebooks/               # Jupyter experiments
â”œâ”€â”€ ğŸ³ docker-compose.yaml     # Service orchestration
â”œâ”€â”€ ğŸ”§ Makefile                # Development commands
â””â”€â”€ ğŸ“‹ README.md               # This file
```

ğŸ“– **Detailed structure**: [Architecture Guide â†’ Project Structure](docs/ARCHITECTURE.md#project-structure)

---

## **Conclusion & future improvements**

This project demonstrates the application of a Convolutional Neural Network (CNN) for music genre classification using the GTZAN dataset. The relatively high accuracy achieved (> 75% on validation and test sets) highlights the strength of CNNs in extracting and leveraging audio features like MFCCs for genre prediction.

However, while the GTZAN dataset has been foundational in advancing music genre classification, it's essential to be aware of its limitations (limited diversity, quality issues, overuse and overfitting). Researchers and developers often use additional or alternative datasets to achieve more robust and generalizable results.

Future improvements could focus on:

- Data Augmentation: Enhancing the dataset with techniques like pitch shifting, time stretching, or adding noise to increase diversity.
- Advanced Architectures: Exploring models like spectrogram-based transformers or hybrid CNN-RNN architectures for improved feature extraction and temporal modeling.
- Dataset Quality: Leveraging larger, more diverse, and well-labeled datasets to enhance robustness.
- Feature Engineering: Experimenting with additional audio features beyond MFCCs, such as chroma features or spectral contrast.

This project provides a solid foundation for music genre classification while acknowledging opportunities for refinement and further exploration.



## ğŸ“ **Learning Resources**

### **ğŸ“š Understand the Technologies**
- **[CNN for Audio](docs/ARCHITECTURE.md#model-architecture)**: How our model processes MFCC features
- **[MLOps Pipeline](docs/TRAINING.md)**: End-to-end ML workflow automation
- **[Model Monitoring](docs/MONITORING.md)**: Production model observability
- **[API Design](docs/API.md)**: RESTful service architecture

### **ğŸ› ï¸ Hands-On Tutorials**
- **[Training Your Own Model](docs/TRAINING.md#custom-training)**: Modify and retrain
- **[Custom Monitoring](docs/MONITORING.md#custom-dashboards)**: Create your own dashboards  
- **[API Integration](docs/API.md#integration-examples)**: Integrate with your app
- **[Production Deployment](docs/DEPLOYMENT.md#production)**: Deploy to cloud

### **ğŸ“Š Notebooks & Experiments**
- **[EDA.ipynb](notebooks/EDA.ipynb)**: Exploratory data analysis
- **[data_preparation.ipynb](notebooks/data_preparation.ipynb)**: Feature engineering
- **[model_NN_classification.ipynb](notebooks/model_NN_classification.ipynb)**: Model selection

---

## ğŸ¤ **Contributing**

We welcome contributions! Here's how to get started:

1. **ğŸ“– Read**: [Development Guide](docs/DEVELOPMENT.md)
2. **ğŸ”§ Setup**: `make dev-setup`
3. **âœ… Test**: `make test`
4. **ğŸ¯ Code**: Follow our style guide
5. **ğŸ“¤ Submit**: Create a pull request

### **Quick Contribution Commands**
```bash
make format        # Format code
make lint          # Check code quality  
make test          # Run all tests
make ci            # Run full CI pipeline
```

ğŸ“– **Detailed guide**: [Development Guide â†’ Contributing](docs/DEVELOPMENT.md#contributing)

---

## ğŸ“„ **License**

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ **Acknowledgments**

- **GTZAN Dataset**: George Tzanetakis for the foundational music genre dataset
- **MLOps Community**: For inspiring production-ready ML practices
- **Open Source Libraries**: TensorFlow, MLflow, Prefect, Evidently, and more

---

## ğŸ“ **Support & Community**

- **ğŸ› Issues**: [GitHub Issues](https://github.com/arsonor/music-genre-classification-with-deep-learning/issues)
- **ğŸ“§ Contact**: [Linkedin](https://www.linkedin.com/in/martindornic/)
- **ğŸ“– Wiki**: [Project Wiki](https://github.com/arsonor/music-genre-classification-with-deep-learning/wiki)

---

<p align="center">
  <strong>ğŸµ Ready to classify some music? </strong><br>
  <a href="docs/QUICK_START.md">Get Started in 5 Minutes â†’</a>
</p>